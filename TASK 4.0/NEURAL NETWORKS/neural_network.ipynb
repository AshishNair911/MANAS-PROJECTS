{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8c272578-c94a-4105-86c6-a742f4da8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with one hidden layer.\n",
    "        \"\"\"\n",
    "        # Weights and biases initialization\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01  # Input to hidden layer\n",
    "        self.b1 = np.zeros((1, hidden_size))                      # Bias for hidden layer\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01  # Hidden to output layer\n",
    "        self.b2 = np.zeros((1, output_size))                      # Bias for output layer\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        Sigmoid activation function.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, a):\n",
    "        \"\"\"\n",
    "        Derivative of the sigmoid activation function.\n",
    "        \"\"\"\n",
    "        return a * (1 - a)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        \"\"\"\n",
    "        Softmax activation function for output layer.\n",
    "        \"\"\"\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Stability trick\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute cross-entropy loss.\n",
    "        \"\"\"\n",
    "        m = y_true.shape[0]  # Number of samples\n",
    "        loss = -np.sum(y_true * np.log(y_pred + 1e-9)) / m  # Add small value for numerical stability\n",
    "        return loss\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        \"\"\"\n",
    "        Train the neural network using gradient descent.\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            z1 = np.dot(X, self.W1) + self.b1\n",
    "            a1 = self.sigmoid(z1)\n",
    "            z2 = np.dot(a1, self.W2) + self.b2\n",
    "            a2 = self.softmax(z2)  # Output layer\n",
    "\n",
    "            # Compute loss\n",
    "            loss = self.compute_loss(y, a2)\n",
    "\n",
    "            # Backward pass\n",
    "            m = X.shape[0]  # Number of samples\n",
    "            dz2 = a2 - y\n",
    "            dW2 = np.dot(a1.T, dz2) / m\n",
    "            db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "\n",
    "            da1 = np.dot(dz2, self.W2.T)\n",
    "            dz1 = da1 * self.sigmoid_derivative(a1)\n",
    "            dW1 = np.dot(X.T, dz1) / m\n",
    "            db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.W1 -= learning_rate * dW1\n",
    "            self.b1 -= learning_rate * db1\n",
    "            self.W2 -= learning_rate * dW2\n",
    "            self.b2 -= learning_rate * db2\n",
    "\n",
    "            # Print loss every 100 epochs\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict probabilities for each class.\n",
    "        \"\"\"\n",
    "        z1 = np.dot(X, self.W1) + self.b1\n",
    "        a1 = self.sigmoid(z1)\n",
    "        z2 = np.dot(a1, self.W2) + self.b2\n",
    "        return self.softmax(z2)  # Probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "866965c0-2847-4d93-a043-0d38719f7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b31c050b-2126-4ba3-a1a7-8dd0083ce514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(image_folder, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(image_folder))  # Sorted list of subfolder names\n",
    "\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        class_folder = os.path.join(image_folder, class_name)\n",
    "        if not os.path.isdir(class_folder):\n",
    "            print(f\"Skipping non-folder item: {class_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing images in class folder: {class_folder}\")\n",
    "        for image_file in os.listdir(class_folder):\n",
    "            if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(class_folder, image_file)\n",
    "                try:\n",
    "                    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "                    img = img.resize((image_size, image_size))  # Resize image\n",
    "                    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
    "                    images.append(img_array.flatten())  # Flatten image\n",
    "                    labels.append(class_index)  # Assign class label\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {image_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping non-image file: {image_file}\")\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images with {len(labels)} labels.\")\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ecc5049f-9e6c-44bb-939e-5267d259b99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\maila\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\maila\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c2e08fcd-0c5c-4026-b339-0c993eefb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4e411fad-896e-4d41-8f71-b8af515df1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_and_labels(zip_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        list_of_files = zip_ref.namelist()\n",
    "\n",
    "        for file_name in list_of_files:\n",
    "            path_parts = file_name.split('/')\n",
    "            if len(path_parts) > 1 and path_parts[-1].endswith('.png'):\n",
    "                subfolder_name = path_parts[-2]  # Class name is the subfolder name\n",
    "                \n",
    "                # Read image\n",
    "                in_bytes = zip_ref.read(file_name)\n",
    "                img = cv2.imdecode(np.frombuffer(in_bytes, np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (28, 28))  # Resize to 28x28\n",
    "                img = img / 255.0  # Normalize pixel values\n",
    "\n",
    "                images.append(img.flatten())  # Flatten the image\n",
    "                labels.append(subfolder_name)  # Append the class name\n",
    "\n",
    "    # Ensure we return the extracted data\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ed0129ec-9ad0-4bc8-a217-1a9390eb26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"C:/Users/maila/OneDrive/Desktop/Manas/task4/Train.zip\"\n",
    "X,y = extract_images_and_labels(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "86fd208c-a569-4767-a6e3-d5eab252ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 4000\n",
      "Number of labels: 4000\n",
      "Unique classes: ['Jade' 'James' 'Jane' 'Joel' 'Jovi']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images: {X.shape[0]}\")\n",
    "print(f\"Number of labels: {len(y)}\")\n",
    "print(f\"Unique classes: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cc25f753-4dd0-4423-a30c-ab6bb5c67b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [1 1 1 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_numeric = le.fit_transform(y)\n",
    "print(f\"Encoded labels: {y_numeric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ab6b7307-5323-4c8c-9ab0-26ecb3d72090",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_numeric))\n",
    "y_one_hot = np.eye(num_classes)[y_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "89a577a3-83e9-4a26-9842-3dc0eb7fce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 3200, Testing samples: 800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bc2aaf05-7734-4763-af11-11a6b671ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 1.5773\n",
      "Epoch 200/1000, Loss: 1.3480\n",
      "Epoch 300/1000, Loss: 1.0824\n",
      "Epoch 400/1000, Loss: 0.8525\n",
      "Epoch 500/1000, Loss: 0.6782\n",
      "Epoch 600/1000, Loss: 0.5638\n",
      "Epoch 700/1000, Loss: 0.4859\n",
      "Epoch 800/1000, Loss: 0.4293\n",
      "Epoch 900/1000, Loss: 0.3863\n",
      "Epoch 1000/1000, Loss: 0.3525\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(input_size=28*28, hidden_size=32, output_size=num_classes)\n",
    "nn.train(X_train, y_train, epochs=1000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a120cac6-9c1e-469d-8bed-3c105094eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions: (800, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of predictions: {predictions.shape}\")\n",
    "predicted_classes = np.argmax(predictions, axis=0) if len(predictions.shape) == 1 else np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8294387f-4224-4447-a588-2d9ee879550c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions: (800, 5)\n",
      "Test accuracy: 91.38%\n"
     ]
    }
   ],
   "source": [
    "predictions = nn.predict(X_test)  # Ensure this outputs probabilities for each class\n",
    "print(f\"Shape of predictions: {predictions.shape}\")\n",
    "\n",
    "# Get predicted and true classes\n",
    "if len(predictions.shape) == 1:  # Binary classification\n",
    "    predicted_classes = (predictions >= 0.5).astype(int)\n",
    "else:  # Multi-class classification\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "16cba906-cbb5-479f-8e0d-2f7d2b229339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICITING ON TEST.ZIP FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f0574933-30a0-4813-968c-00d6a116fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path_2 = \"C:/Users/maila/OneDrive/Desktop/Manas/task4/Test.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f4bbf2bf-8ab6-4a67-a84c-d5b3f2a0c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = extract_images_and_labels(zip_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2e9638b7-0de7-4ead-99b1-0804219a5f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1000\n",
      "Number of labels: 1000\n",
      "Unique classes: ['Jade' 'James' 'Jane' 'Joel' 'Jovi']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images: {X.shape[0]}\")\n",
    "print(f\"Number of labels: {len(y)}\")\n",
    "print(f\"Unique classes: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "eab7198f-6d0c-41b9-83f6-5b8e31aa4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
    "y_one_hot = encoder.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aa89cf7e-95a5-4cf6-888d-aa08cf8fa2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "75cdfc9e-6de4-4d74-bb90-a1a96d82e99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 91.40%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_one_hot, axis=1))\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1271c9e-fa2d-42d5-bff8-0b208573b5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
